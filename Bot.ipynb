{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1295e785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00468bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m __          ___   ____    __    ____ ____    ____  _______ .______            .______     ______   .___________.\n",
      "|  |        /   \\  \\   \\  /  \\  /   / \\   \\  /   / |   ____||   _  \\           |   _  \\   /  __  \\  |           |\n",
      "|  |       /  ^  \\  \\   \\/    \\/   /   \\   \\/   /  |  |__   |  |_)  |    ______|  |_)  | |  |  |  | `---|  |----`\n",
      "|  |      /  /_\\  \\  \\            /     \\_    _/   |   __|  |      /    |______|   _  <  |  |  |  |     |  |     \n",
      "|  `----./  _____  \\  \\    /\\    /        |  |     |  |____ |  |\\  \\----.      |  |_)  | |  `--'  |     |  |     \n",
      "|_______/__/     \\__\\  \\__/  \\__/         |__|     |_______|| _| `._____|      |______/   \\______/      |__|     \n",
      "                                                                                                                 \n",
      "\u001b[0m\n",
      "\n",
      "ðŸ“„ Loading documents and building knowledge base...\n",
      "âœ… Vector DB ready. Launching QA Chat...\n",
      "\n",
      "\n",
      "ðŸŸ¢ You can start chatting now. Type 'Exit the Chatbot' to end the session.\n",
      "\n",
      "ðŸ§  You: According to Article 12, what is protected against arbitrary interference?\n",
      "ðŸ¤– Bot:  According to Article 12, privacy, family, home, and correspondence are protected against arbitrary interference.\n",
      "\n",
      "ðŸ§  You: Which forms of mistreatment are explicitly prohibited by Article 5?\n",
      "ðŸ¤– Bot:  Torture, cruel, inhuman or degrading treatment or punishment are explicitly prohibited by Article 5.\n",
      "\n",
      "ðŸ§  You: Can human rights be used to justify acts against the UN?\n",
      "ðŸ¤– Bot:  No, human rights cannot be used to justify acts against the United Nations as it is established in the Universal Declaration of Human Rights that all individuals have inherent dignity and equal and inalienable rights, but these rights should be protected by the rule of law and not used to undermine international cooperation or the principles upheld by the UN.\n",
      "\n",
      "\n",
      "ðŸ‘‹ Exiting... Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Requirements ===\n",
    "# pip install -q langchain langchain-community langchain-core langchainhub sentence-transformers faiss-cpu pypdf python-dotenv pyfiglet termcolor\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pyfiglet import figlet_format\n",
    "from termcolor import colored\n",
    "\n",
    "# === Load environment (.env should have HF_TOKEN) ===\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")  # Only for embeddings\n",
    "\n",
    "# === Stylish Heading ===\n",
    "def stylish_heading():\n",
    "    title = figlet_format(\"Lawyer-Bot\", font=\"starwars\", width=1000)\n",
    "    print(colored(title, \"green\"))\n",
    "\n",
    "# === Load Local Ollama Model (Offline Mistral) ===\n",
    "def load_llm():\n",
    "    llm = ChatOllama(\n",
    "        model=\"mistral:instruct\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "# === Custom Prompt ===\n",
    "CUSTOM_PROMPT_TEMPLATE = \"\"\"\n",
    "Use the pieces of information provided in the context to answer the user's question.\n",
    "If you don't know the answer, say you don't know â€” do not make it up.\n",
    "Only refer to the context provided.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Start the answer directly without unnecessary text.\n",
    "\"\"\"\n",
    "\n",
    "def set_custom_prompt(template):\n",
    "    return PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# === PDF Document Loader ===\n",
    "def load_pdf_files(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# === Split into Chunks ===\n",
    "def create_chunks(docs):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "# === Embedding Model (Requires HF Token) ===\n",
    "def get_embedding_model():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# === Save to FAISS DB ===\n",
    "def build_vector_db(chunks, embedding_model, db_path):\n",
    "    db = FAISS.from_documents(chunks, embedding_model)\n",
    "    db.save_local(db_path)\n",
    "\n",
    "# === Load from FAISS DB ===\n",
    "def load_vector_db(db_path, embedding_model):\n",
    "    return FAISS.load_local(db_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# === Setup QA Chain ===\n",
    "def setup_qa_chain(llm, db, prompt):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(search_kwargs={'k': 3}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "# === Paths ===\n",
    "DATA_PATH = \"data/\"\n",
    "DB_FAISS_PATH = \"vectorstore/db_faiss\"\n",
    "\n",
    "# === Pipeline Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    stylish_heading()\n",
    "    print(\"\\nðŸ“„ Loading documents and building knowledge base...\")\n",
    "\n",
    "    documents = load_pdf_files(DATA_PATH)\n",
    "    text_chunks = create_chunks(documents)\n",
    "    embedding_model = get_embedding_model()\n",
    "\n",
    "    if not os.path.exists(DB_FAISS_PATH):\n",
    "        print(\"ðŸ”§ Creating FAISS database...\")\n",
    "        build_vector_db(text_chunks, embedding_model, DB_FAISS_PATH)\n",
    "\n",
    "    print(\"âœ… Vector DB ready. Launching QA Chat...\\n\")\n",
    "\n",
    "    db = load_vector_db(DB_FAISS_PATH, embedding_model)\n",
    "    llm = load_llm()\n",
    "    qa_chain = setup_qa_chain(llm, db, set_custom_prompt(CUSTOM_PROMPT_TEMPLATE))\n",
    "\n",
    "    print(\"\\nðŸŸ¢ You can start chatting now. Type 'Exit the Chatbot' to end the session.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"ðŸ§  You: \")\n",
    "        if user_query.strip().lower() == \"exit the chatbot\":\n",
    "            print(\"\\nðŸ‘‹ Exiting... Have a great day!\\n\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            print(f\"ðŸ§  You: {user_query}\")  # Explicitly printing user query\n",
    "            result = qa_chain.invoke({\"query\": user_query})\n",
    "            print(f\"ðŸ¤– Bot: {result['result']}\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"âŒ Error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
