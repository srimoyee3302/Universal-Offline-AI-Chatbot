# ğŸŒ Universal Offline AI Chatbot

> Build your own domain-specific chatbot â€” offline, modular, and blazing fast.

[![Python](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/release/python-3110/)
![LangChain](https://img.shields.io/badge/LangChain-%E2%9C%94-green)
![Docker](https://img.shields.io/badge/Docker-ready-blue)
![Offline](https://img.shields.io/badge/Offline-LLM-orange)

The **Universal Offline AI Chatbot** is a privacy-respecting, offline-ready assistant that can chat over **any set of PDFs**. Itâ€™s ideal for legal, cybersecurity, academic, enterprise, or technical domains.

It uses a **locally hosted LLM** (`mistral:instruct` via [Ollama](https://ollama.com)) and **semantic search** powered by HuggingFace embeddings and FAISS. You get **fast, accurate responses**, without sending anything to the cloud.

> **GitHub Link:** [https://github.com/AdityaBhatt3010/Universal-Offline-AI-Chatbot](https://github.com/AdityaBhatt3010/Universal-Offline-AI-Chatbot) <br/>
> **DockerHub Link:** [https://hub.docker.com/r/adityabhatt3010/ai-chatbot](https://hub.docker.com/r/adityabhatt3010/ai-chatbot)

---

## âœ¨ Highlights

* ğŸ” Fully **offline-capable** with local LLM (via Ollama)
* ğŸ“„ Works out-of-the-box with your **PDFs**
* ğŸ§  **Semantic vector search** using `all-MiniLM-L6-v2`
* âš¡ï¸ Fast and responsive using **FAISS** backend
* ğŸ§© Modular, extendable architecture (Streamlit frontend + CLI)
* ğŸ³ Docker-ready for deployment
* ğŸ“¸ UI Preview with screenshots
* âœ… Built-in CI/CD check via GitHub Actions
* ğŸ¯ Fully reproducible setup via PowerShell script or Docker

---

## ğŸ§± Tech Stack

| Layer        | Stack                                       |
| ------------ | ------------------------------------------- |
| LLM          | `mistral:instruct` via Ollama               |
| Embeddings   | `all-MiniLM-L6-v2` via SentenceTransformers |
| Vector Store | FAISS (in-memory + disk)                    |
| Framework    | LangChain (v0.2+)                           |
| Language     | Python 3.11+                                |
| UI           | Streamlit                                   |
| Container    | Docker                                      |
| CI/CD        | GitHub Actions (`.github/workflows/python.yml`) |

> âš ï¸ HuggingFace Token is required to fetch the embedding model once. It's cached locally afterward.

Example `.env`:

```env
HF_TOKEN=your_huggingface_token_here
````

---

## ğŸ’¡ Use Cases

| Chatbot Type        | Add These PDFs                     |
| ------------------- | ---------------------------------- |
| ğŸ‘¨â€âš–ï¸ LawyerBot     | Legal, Constitution, HR documents  |
| ğŸ§¬ ResearchBot      | Whitepapers, scientific papers     |
| ğŸ›¡ï¸ CyberSecBot     | SOC2, GDPR, ISO27001, NIST docs    |
| ğŸ“š EdTechBot        | Notes, textbooks, question banks   |
| ğŸ§‘â€ğŸ’¼ HR/CompanyBot | SOPs, onboarding docs, HR policies |

---

## ğŸ“ Project Structure

```
Universal-Offline-AI-Chatbot/
â”‚
â”œâ”€â”€ data/                   # Place your PDF documents here
â”‚   â””â”€â”€ Try.pdf
â”‚
â”œâ”€â”€ Screenshots/           # UI snapshots
â”‚   â”œâ”€â”€ Loading_Screen.png
â”‚   â””â”€â”€ Running_the_Model.png
â”‚
â”œâ”€â”€ src/                   # Modular source code
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ qa_chain.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ vectorstore.py
â”‚
â”œâ”€â”€ vectorstore/           # Local FAISS vector index
â”‚   â””â”€â”€ db_faiss/
â”‚
â”œâ”€â”€ Bot.py                 # CLI script
â”œâ”€â”€ Bot.ipynb              # Jupyter notebook version
â”œâ”€â”€ main.py                # Entry-point (optional)
â”œâ”€â”€ streamlit_app.py       # Frontend UI (Streamlit)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ setup.ps1              # PowerShell setup script
â”œâ”€â”€ Dockerfile             # Docker image definition
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                   # Contains HF_TOKEN
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ§° Setup Instructions

### ğŸ–¥ï¸ One-Click Setup (Windows Only)

```powershell
.\setup.ps1
```

This will:

* Create virtual env
* Install dependencies
* Pull Mistral via Ollama
* Ask for Hugging Face token
* Build Docker image

---

### ğŸ›  Manual Setup

1. **Install Python Requirements**

```bash
pip install -r requirements.txt
```

2. **Install & Pull Ollama Model**

```bash
ollama pull mistral:instruct
```

3. **Set HuggingFace Token (First Time Only)**

```bash
export HUGGINGFACEHUB_API_TOKEN=your_token      # macOS/Linux
set HUGGINGFACEHUB_API_TOKEN=your_token         # Windows CMD
```

4. **Run the CLI Bot**

```bash
python Bot.py
```

---

## ğŸŒ Run with Streamlit Frontend

```bash
streamlit run streamlit_app.py
```

### ğŸ“¸ Streamlit Preview

#### â³ Loading Screen

![Loading Screen](./Screenshots/Loading_Screen.png)

#### ğŸ¤– Chat in Action

![Running the Model](./Screenshots/Running_the_Model.png)

---

## ğŸ³ Docker Support

### Prerequisites

* Docker installed & running
* `.env` file containing `HF_TOKEN` (Hugging Face token)

---

### ğŸ› ï¸ Docker Build & Run

To build and run the chatbot using Docker, follow these steps:

1. **Build the Docker image**:

   ```bash
   docker build -t ai-chatbot .
   ```

2. **Run the container** (with volume mount and token):

   ```bash
   docker run -p 8501:8501 --env-file .env -v ${PWD}/data:/app/data ai-chatbot
   ```

   This will:

   * Map the container's port `8501` to local `8501`
   * Use your local `.env` for `HF_TOKEN`
   * Mount the `data/` folder into the container for access to PDFs

> Access the chatbot at [http://localhost:8501](http://localhost:8501)

### ğŸ“¸ Screenshot: 

#### ğŸ³ Building the Image

![Docker Build and Run](./Screenshots/Docker_Build_Run.png)

---

Let me know if you want the actual screenshot file names changed or if youâ€™d like a quick CLI script to generate and store those screenshots automatically during your next run.


---

## ğŸ”„ Using Your Own PDFs

```bash
# Replace default file(s)
mv your_files/*.pdf ./data/

# Re-run the bot or restart Streamlit
python Bot.py
```

Automatically re-indexes your new documents using FAISS.

---

## ğŸ§ª Sample Interaction

```
ğŸ§  You: What does Article 21 state?

ğŸ¤– Bot: Article 21 of the Indian Constitution guarantees the protection of life and personal liberty...
```

---

## ğŸ§‘â€ğŸ’» Author

**Aditya Bhatt** <br/>
Cybersecurity Specialist | VAPT Expert | OSS Contributor <br/>
[GitHub](https://github.com/AdityaBhatt3010) | [Medium](https://medium.com/@adityabhatt3010) <br/>

---
